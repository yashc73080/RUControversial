{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9dea4277",
   "metadata": {},
   "source": [
    "## Data Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b53b47e",
   "metadata": {},
   "source": [
    "In this notebook, we process our data in aita_posts.csv so that it can be fed to our BERT model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be9e412",
   "metadata": {},
   "source": [
    "### Necessary Imports Below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "adbcf1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e7be25f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Data/aita_raw.csv')\n",
    "\n",
    "df.drop(columns=['timestamp', 'edited', 'is_asshole'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f004a0",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde755f5",
   "metadata": {},
   "source": [
    "Here, we will begin preprocessing each reddit post. Specifically, the code below will do the following to the post title and body\n",
    "\n",
    "- Stop word removal\n",
    "- Lowercasing\n",
    "- Lemminization\n",
    "- Punctuation Removal\n",
    "\n",
    "Doing this will remove irrelevant and noisy text, avoid hitting token length limits, normalize slangy/repetitive posts, and keep the BERT model efficient and focused.\n",
    "\n",
    "Afterwards, the title and body will be combined and added a new column called \"combined\". Then, we will drop the title, selftext, and other unecessary columns to save space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a7e90701",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>verdict</th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>combined_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1ytxov</td>\n",
       "      <td>asshole</td>\n",
       "      <td>52</td>\n",
       "      <td>13.0</td>\n",
       "      <td>[AITA] I wrote an explanation in TIL and came ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1yu29c</td>\n",
       "      <td>asshole</td>\n",
       "      <td>140</td>\n",
       "      <td>27.0</td>\n",
       "      <td>[AITA] Threw my parent's donuts away My parent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1yu8hi</td>\n",
       "      <td>not the asshole</td>\n",
       "      <td>74</td>\n",
       "      <td>15.0</td>\n",
       "      <td>I told a goth girl she looked like a clown. I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1yuc78</td>\n",
       "      <td>everyone sucks</td>\n",
       "      <td>22</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[AItA]: Argument I had with another redditor i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1yueqb</td>\n",
       "      <td>not the asshole</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[AITA] I let my story get a little long and bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>aex06k</td>\n",
       "      <td>not the asshole</td>\n",
       "      <td>8</td>\n",
       "      <td>9.0</td>\n",
       "      <td>AITA for not wanting to go to prom? i’m a juni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>aex3da</td>\n",
       "      <td>not the asshole</td>\n",
       "      <td>16</td>\n",
       "      <td>28.0</td>\n",
       "      <td>AITA for not letting my brother use my compute...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>aex4r5</td>\n",
       "      <td>asshole</td>\n",
       "      <td>31</td>\n",
       "      <td>80.0</td>\n",
       "      <td>AITA for despising this girl? AITA??\\n\\nSo I k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>aex7pl</td>\n",
       "      <td>not the asshole</td>\n",
       "      <td>11</td>\n",
       "      <td>13.0</td>\n",
       "      <td>AITA becuase a christmas gift I ordered for my...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>aex8zo</td>\n",
       "      <td>not the asshole</td>\n",
       "      <td>5</td>\n",
       "      <td>14.0</td>\n",
       "      <td>AITA for no longer feeling attracted to a part...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id          verdict  score  num_comments  \\\n",
       "0     1ytxov          asshole     52          13.0   \n",
       "1     1yu29c          asshole    140          27.0   \n",
       "2     1yu8hi  not the asshole     74          15.0   \n",
       "3     1yuc78   everyone sucks     22           3.0   \n",
       "4     1yueqb  not the asshole      6           4.0   \n",
       "...      ...              ...    ...           ...   \n",
       "9995  aex06k  not the asshole      8           9.0   \n",
       "9996  aex3da  not the asshole     16          28.0   \n",
       "9997  aex4r5          asshole     31          80.0   \n",
       "9998  aex7pl  not the asshole     11          13.0   \n",
       "9999  aex8zo  not the asshole      5          14.0   \n",
       "\n",
       "                                          combined_text  \n",
       "0     [AITA] I wrote an explanation in TIL and came ...  \n",
       "1     [AITA] Threw my parent's donuts away My parent...  \n",
       "2     I told a goth girl she looked like a clown. I ...  \n",
       "3     [AItA]: Argument I had with another redditor i...  \n",
       "4     [AITA] I let my story get a little long and bo...  \n",
       "...                                                 ...  \n",
       "9995  AITA for not wanting to go to prom? i’m a juni...  \n",
       "9996  AITA for not letting my brother use my compute...  \n",
       "9997  AITA for despising this girl? AITA??\\n\\nSo I k...  \n",
       "9998  AITA becuase a christmas gift I ordered for my...  \n",
       "9999  AITA for no longer feeling attracted to a part...  \n",
       "\n",
       "[10000 rows x 5 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load spaCy and disable unnecessary components\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=['parser', 'ner'])\n",
    "nlp.max_length = 60000000\n",
    "\n",
    "# Enforce strs in cols\n",
    "df['body'] = df['body'].fillna('').astype(str)\n",
    "df['title'] = df['title'].fillna('').astype(str)\n",
    "\n",
    "\n",
    "# Add processed texts as new column\n",
    "df['combined_text'] = df['title'] + ' ' + df['body']\n",
    "\n",
    "# Drop the body and title columns\n",
    "df.drop(columns=['body', 'title'], inplace=True)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eefe41f",
   "metadata": {},
   "source": [
    "After the cleaning, we save the cleaned data in the Data Subdirectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1776f85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the preprocessed DataFrame to a new CSV file\n",
    "df.to_csv(\"../Data/aita_posts_preprocessed.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc060e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
