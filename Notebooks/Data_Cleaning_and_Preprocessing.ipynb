{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9dea4277",
   "metadata": {},
   "source": [
    "## Data Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b53b47e",
   "metadata": {},
   "source": [
    "In this notebook, we process our data in aita_posts.csv so that it can be fed to our BERT model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be9e412",
   "metadata": {},
   "source": [
    "### Necessary Imports Below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "adbcf1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e7be25f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>verdict</th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1ytxov</td>\n",
       "      <td>[AITA] I wrote an explanation in TIL and came ...</td>\n",
       "      <td>[Here is the post in question](http://www.redd...</td>\n",
       "      <td>asshole</td>\n",
       "      <td>52</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1yu29c</td>\n",
       "      <td>[AITA] Threw my parent's donuts away</td>\n",
       "      <td>My parents are diabetic, morbidly obese, and a...</td>\n",
       "      <td>asshole</td>\n",
       "      <td>140</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1yu8hi</td>\n",
       "      <td>I told a goth girl she looked like a clown.</td>\n",
       "      <td>I was four.</td>\n",
       "      <td>not the asshole</td>\n",
       "      <td>74</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1yuc78</td>\n",
       "      <td>[AItA]: Argument I had with another redditor i...</td>\n",
       "      <td>http://www.reddit.com/r/HIMYM/comments/1vvfkq/...</td>\n",
       "      <td>everyone sucks</td>\n",
       "      <td>22</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1yueqb</td>\n",
       "      <td>[AITA] I let my story get a little long and bo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>not the asshole</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>aex06k</td>\n",
       "      <td>AITA for not wanting to go to prom?</td>\n",
       "      <td>i’m a junior in high school and i’ve been to p...</td>\n",
       "      <td>not the asshole</td>\n",
       "      <td>8</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>aex3da</td>\n",
       "      <td>AITA for not letting my brother use my computer?</td>\n",
       "      <td>Hey reddit am I not the asshole for letting my...</td>\n",
       "      <td>not the asshole</td>\n",
       "      <td>16</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>aex4r5</td>\n",
       "      <td>AITA for despising this girl?</td>\n",
       "      <td>AITA??\\n\\nSo I know a girl who got pregnant be...</td>\n",
       "      <td>asshole</td>\n",
       "      <td>31</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>aex7pl</td>\n",
       "      <td>AITA becuase a christmas gift I ordered for my...</td>\n",
       "      <td>Ok so long story here, I decided back in Novem...</td>\n",
       "      <td>not the asshole</td>\n",
       "      <td>11</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>aex8zo</td>\n",
       "      <td>AITA for no longer feeling attracted to a part...</td>\n",
       "      <td>A bit of background: I am in my 30s and am dec...</td>\n",
       "      <td>not the asshole</td>\n",
       "      <td>5</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                              title  \\\n",
       "0     1ytxov  [AITA] I wrote an explanation in TIL and came ...   \n",
       "1     1yu29c               [AITA] Threw my parent's donuts away   \n",
       "2     1yu8hi        I told a goth girl she looked like a clown.   \n",
       "3     1yuc78  [AItA]: Argument I had with another redditor i...   \n",
       "4     1yueqb  [AITA] I let my story get a little long and bo...   \n",
       "...      ...                                                ...   \n",
       "9995  aex06k                AITA for not wanting to go to prom?   \n",
       "9996  aex3da   AITA for not letting my brother use my computer?   \n",
       "9997  aex4r5                      AITA for despising this girl?   \n",
       "9998  aex7pl  AITA becuase a christmas gift I ordered for my...   \n",
       "9999  aex8zo  AITA for no longer feeling attracted to a part...   \n",
       "\n",
       "                                                   body          verdict  \\\n",
       "0     [Here is the post in question](http://www.redd...          asshole   \n",
       "1     My parents are diabetic, morbidly obese, and a...          asshole   \n",
       "2                                           I was four.  not the asshole   \n",
       "3     http://www.reddit.com/r/HIMYM/comments/1vvfkq/...   everyone sucks   \n",
       "4                                                   NaN  not the asshole   \n",
       "...                                                 ...              ...   \n",
       "9995  i’m a junior in high school and i’ve been to p...  not the asshole   \n",
       "9996  Hey reddit am I not the asshole for letting my...  not the asshole   \n",
       "9997  AITA??\\n\\nSo I know a girl who got pregnant be...          asshole   \n",
       "9998  Ok so long story here, I decided back in Novem...  not the asshole   \n",
       "9999  A bit of background: I am in my 30s and am dec...  not the asshole   \n",
       "\n",
       "      score  num_comments  \n",
       "0        52          13.0  \n",
       "1       140          27.0  \n",
       "2        74          15.0  \n",
       "3        22           3.0  \n",
       "4         6           4.0  \n",
       "...     ...           ...  \n",
       "9995      8           9.0  \n",
       "9996     16          28.0  \n",
       "9997     31          80.0  \n",
       "9998     11          13.0  \n",
       "9999      5          14.0  \n",
       "\n",
       "[10000 rows x 6 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../../aita_clean.csv', nrows=10000)\n",
    "\n",
    "df.drop(columns=['timestamp', 'edited', 'is_asshole'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f004a0",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde755f5",
   "metadata": {},
   "source": [
    "Here, we will begin preprocessing each reddit post. Specifically, the code below will do the following to the post title and body\n",
    "\n",
    "- Stop word removal\n",
    "- Lowercasing\n",
    "- Lemminization\n",
    "- Punctuation Removal\n",
    "\n",
    "Doing this will remove irrelevant and noisy text, avoid hitting token length limits, normalize slangy/repetitive posts, and keep the BERT model efficient and focused.\n",
    "\n",
    "Afterwards, the title and body will be combined and added a new column called \"combined\". Then, we will drop the title, selftext, and other unecessary columns to save space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e90701",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing posts: 100%|██████████| 10000/10000 [09:41<00:00, 17.20it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load spaCy and disable unnecessary components\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=['parser', 'ner'])\n",
    "nlp.max_length = 60000000\n",
    "\n",
    "# Enforce strs in cols\n",
    "df['body'] = df['body'].fillna('').astype(str)\n",
    "df['title'] = df['title'].fillna('').astype(str)\n",
    "\n",
    "# Define preprocessing functions\n",
    "def preprocess_text(text):\n",
    "    doc = nlp(text)\n",
    "    return [token.lemma_.lower() for token in doc if not token.is_stop and not token.is_punct]\n",
    "\n",
    "def process_row(row):\n",
    "    try:\n",
    "        title_tokens = preprocess_text(row['title'])\n",
    "        body_tokens = preprocess_text(row['body'])\n",
    "        return ' '.join(title_tokens + body_tokens)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing row: {e}\")\n",
    "        return ''\n",
    "\n",
    "# Process rows with visible progress bar\n",
    "processed_texts = []\n",
    "for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing posts\"):\n",
    "    processed_text = process_row(row)\n",
    "    processed_texts.append(processed_text)\n",
    "\n",
    "# Add processed texts as new column\n",
    "df['combined_text'] = processed_texts\n",
    "\n",
    "# Drop the body and title columns\n",
    "df.drop(columns=['body', 'title'], inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eefe41f",
   "metadata": {},
   "source": [
    "After the cleaning, we save the cleaned data in the Data Subdirectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1776f85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the preprocessed DataFrame to a new CSV file\n",
    "df.to_csv(\"../Data/aita_posts_preprocessed.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
