{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a1f9e1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "from transformers import BertModel, BertTokenizer\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87c442b",
   "metadata": {},
   "source": [
    "## Connecting to Supabase + Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "de965e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection successful!\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables from .env\n",
    "load_dotenv()\n",
    "\n",
    "# Fetch variables\n",
    "USER = os.getenv(\"user\")\n",
    "PASSWORD = os.getenv(\"password\")\n",
    "HOST = os.getenv(\"host\")\n",
    "PORT = os.getenv(\"port\")\n",
    "DBNAME = os.getenv(\"dbname\")\n",
    "\n",
    "# Connect to the database\n",
    "try:\n",
    "    connection = psycopg2.connect(\n",
    "        user=USER,\n",
    "        password=PASSWORD,\n",
    "        host=HOST,\n",
    "        port=PORT,\n",
    "        dbname=DBNAME\n",
    "    )\n",
    "    print(\"Connection successful!\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Failed to connect: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7fb10a16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bchen\\AppData\\Local\\Temp\\ipykernel_1256\\1279328471.py:2: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql_query(query, connection)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>combined</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1k6igkk</td>\n",
       "      <td>aita freak mom watch brother 14f 13 m brother ...</td>\n",
       "      <td>Not the A-hole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1k6hyib</td>\n",
       "      <td>aita ask brother m19 voice chat friend night f...</td>\n",
       "      <td>Not the A-hole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1k6gmp6</td>\n",
       "      <td>aita let bf use desk chair 34nb bf(35 m live 9...</td>\n",
       "      <td>Not the A-hole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1k6g0wj</td>\n",
       "      <td>aita tell wife quit smoking asshole tell wife ...</td>\n",
       "      <td>Not the A-hole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1k6flrt</td>\n",
       "      <td>aita share switch 14f young sister 12f switch ...</td>\n",
       "      <td>Not the A-hole</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   post_id                                           combined           label\n",
       "0  1k6igkk  aita freak mom watch brother 14f 13 m brother ...  Not the A-hole\n",
       "1  1k6hyib  aita ask brother m19 voice chat friend night f...  Not the A-hole\n",
       "2  1k6gmp6  aita let bf use desk chair 34nb bf(35 m live 9...  Not the A-hole\n",
       "3  1k6g0wj  aita tell wife quit smoking asshole tell wife ...  Not the A-hole\n",
       "4  1k6flrt  aita share switch 14f young sister 12f switch ...  Not the A-hole"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"SELECT post_id, combined, label FROM aita_posts LIMIT 500;\"\n",
    "df = pd.read_sql_query(query, connection)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154a6122",
   "metadata": {},
   "source": [
    "## Testing BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7b53c8",
   "metadata": {},
   "source": [
    "Set up HuggingFace BERT model and load pre-trained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "62dbf546",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7f4594",
   "metadata": {},
   "source": [
    "BERT tokenizer for preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cee8da31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])\n"
     ]
    }
   ],
   "source": [
    "sample_text = \"Reddit posts can sometimes go viral overnight.\"\n",
    "\n",
    "# Tokenize input text\n",
    "inputs = tokenizer(\n",
    "    sample_text,\n",
    "    padding='max_length',\n",
    "    truncation=True,\n",
    "    max_length=128,\n",
    "    return_tensors='pt'  # PyTorch tensors\n",
    ")\n",
    "\n",
    "print(inputs.keys())  # Input IDs and attention mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad8b1a3",
   "metadata": {},
   "source": [
    "## BERT Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90452ada",
   "metadata": {},
   "source": [
    "Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "09436482",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTClassifier(nn.Module):\n",
    "    def __init__(self, dropout=0.3):\n",
    "        super(BERTClassifier, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.classifier = nn.Linear(self.bert.config.hidden_size, 4)  # Binary classification\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.pooler_output\n",
    "        x = self.dropout(pooled_output)\n",
    "        return self.classifier(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107cc71a",
   "metadata": {},
   "source": [
    "Encode labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6bd60b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Asshole' 'Everyone Sucks' 'No A-holes here' 'Not the A-hole']\n"
     ]
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "df['label_encoded'] = label_encoder.fit_transform(df['label'])\n",
    "print(label_encoder.classes_)  # View label mappings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a603f9dd",
   "metadata": {},
   "source": [
    "Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a0801c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "    df['combined'].values, \n",
    "    df['label_encoded'].values, \n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42382651",
   "metadata": {},
   "source": [
    "Tokenize text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fb4fc037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize\n",
    "train_encodings = tokenizer(list(train_texts), truncation=True, padding=True, max_length=128, return_tensors='pt')\n",
    "test_encodings = tokenizer(list(test_texts), truncation=True, padding=True, max_length=128, return_tensors='pt')\n",
    "\n",
    "# Convert labels to tensors\n",
    "train_labels = torch.tensor(train_labels)\n",
    "test_labels = torch.tensor(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2beea1cb",
   "metadata": {},
   "source": [
    "Make dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "03b2eef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RedditDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        item['labels'] = self.labels[idx]\n",
    "        return item\n",
    "\n",
    "train_dataset = RedditDataset(train_encodings, train_labels)\n",
    "test_dataset = RedditDataset(test_encodings, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389d28f6",
   "metadata": {},
   "source": [
    "Setup train and test loaders, and other things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5223ae21",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "model = BERTClassifier()\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23db5051",
   "metadata": {},
   "source": [
    "Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1f4d5bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 10/10 [02:17<00:00, 13.71s/it, loss=1.29]\n",
      "Epoch 1: 100%|██████████| 10/10 [03:56<00:00, 23.65s/it, loss=1.34]\n",
      "Epoch 2: 100%|██████████| 10/10 [01:56<00:00, 11.64s/it, loss=1.33]\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for epoch in range(3):  # Baseline: 3 epochs\n",
    "    loop = tqdm(train_loader, leave=True)\n",
    "    for batch in loop:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        outputs = model(input_ids, attention_mask)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loop.set_description(f'Epoch {epoch}')\n",
    "        loop.set_postfix(loss=loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e4f76307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy: 0.2821\n",
      "Baseline F1-Score: 0.1597\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "predictions, true_labels = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        outputs = model(input_ids, attention_mask)\n",
    "        preds = torch.argmax(outputs, axis=1)\n",
    "\n",
    "        predictions.extend(preds.cpu().numpy())\n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Metrics\n",
    "acc = accuracy_score(true_labels, predictions)\n",
    "f1 = f1_score(true_labels, predictions, average='weighted')\n",
    "\n",
    "print(f'Baseline Accuracy: {acc:.4f}')\n",
    "print(f'Baseline F1-Score: {f1:.4f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs439",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
